{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"ul[class='follow_list']\"}\n  (Session info: chrome=51.0.2704.103)\n  (Driver info: chromedriver=2.22.397929 (fb72fb249a903a0b1041ea71eb4c8b3fa0d9be5a),platform=Mac OS X 10.10.4 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0cfb1932c625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0maccount_followers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m \u001b[0maccount_followers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFollowers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_followers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccount_followers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-0cfb1932c625>\u001b[0m in \u001b[0;36mgetFollowers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"//body/div[1]//a[@class='page next S_txt1 S_line1']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# next button\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mhtml_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ul[class='follow_list']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_tag_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"li\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/selenium/webdriver/remote/webdriver.pyc\u001b[0m in \u001b[0;36mfind_element_by_css_selector\u001b[0;34m(self, css_selector)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#foo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \"\"\"\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcss_selector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_css_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcss_selector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/selenium/webdriver/remote/webdriver.pyc\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    750\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    751\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/selenium/webdriver/remote/webdriver.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    238\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/selenium/webdriver/remote/errorhandler.pyc\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mexception_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mUnexpectedAlertPresentException\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'alert'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"ul[class='follow_list']\"}\n  (Session info: chrome=51.0.2704.103)\n  (Driver info: chromedriver=2.22.397929 (fb72fb249a903a0b1041ea71eb4c8b3fa0d9be5a),platform=Mac OS X 10.10.4 x86_64)\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import sys  \n",
    "import re\n",
    "import pickle\n",
    "import codecs\n",
    "import math\n",
    "import contextlib\n",
    "import selenium.webdriver.support.ui as ui\n",
    "from pyvirtualdisplay import Display\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import json\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "class w_scraper(object): \n",
    "    def login(self,credentialFile):\n",
    "        # Open new window for Chrome, used for testing\n",
    "        self.page = webdriver.Chrome()\n",
    "        self.page.get(\"http://weibo.com/login.php\") # load the login page\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Read in account username and password\n",
    "        for line in credentialFile:\n",
    "            username,password = line.split(\",\")\n",
    "            \n",
    "        #self.page.get(\"http://weibo.com/login.php#_loginLayer_1468518776979\")\n",
    "        #time.sleep(2)\n",
    "        \n",
    "        # Logs into account\n",
    "        # Login button option\n",
    "        login_button = self.page.find_element_by_xpath(\"//body/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[3]/div[2]/ul[1]/li[3]/a\")#(\"//body/div[1]//ul[@class='gn_login_list']/li[3]/a\")#(\"//body/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[3]/div[2]/ul[1]/li[3]/a\")\n",
    "        login_button.click()\n",
    "        time.sleep(3)\n",
    "        \n",
    "        self.page.get(\"http://weibo.com/login.php#_loginLayer_1468518776979\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Sign in with username option\n",
    "        email_button = self.page.find_element_by_xpath(\"//body/div[3]/div[2]/div[3]/div[1]/a[2]\")\n",
    "        email_button.click()\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Enter Username\n",
    "        username_box = self.page.find_element_by_xpath(\"//body/div[3]/div[2]/div[3]/div[3]/div[1]/input\")\n",
    "        username_box.send_keys(username)\n",
    "        \n",
    "        # Enter password\n",
    "        password_box = self.page.find_element_by_xpath(\"//body/div[3]/div[2]/div[3]/div[3]/div[2]/input\")\n",
    "        password_box.send_keys(password)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Hit Enter button\n",
    "        password_box.send_keys(Keys.ENTER)\n",
    "        #enter_button = self.page.find_element_by_xpath(\"//body/div[3]/div[2]/div[3]/div[3]/div[6]/a\")\n",
    "        #enter_button.click()\n",
    "        time.sleep(4)\n",
    "        self.page.get('http://weibo.com/u/2407651573')\n",
    "        time.sleep(4)\n",
    "  \n",
    "    def getFollowers(self):\n",
    "        followers = list()\n",
    "        # Open the file that contains the list of account ID numbers\n",
    "        # for line in open('actual_ids.txt', 'r'):\n",
    "        # account_url = ('http://weibo.com/u/' + line)\n",
    "        \n",
    "        #self.page.get(account_url) # Go to specific account homepage\n",
    "\n",
    "        # Click to go to followers page\n",
    "        follow_button = self.page.find_element_by_xpath(\"//body/div[1]//td[@class='S_line1'][2]/a/strong[@class='W_f18']\")\n",
    "        follow_button.click()\n",
    "\n",
    "        time.sleep(2)\n",
    "        # print out followers on that page\n",
    "        html_list = self.page.find_element_by_css_selector(\"ul[class='follow_list']\")\n",
    "        items = html_list.find_elements_by_tag_name(\"li\")\n",
    "        for item in items:\n",
    "            text = item.text\n",
    "            followers.append(text)\n",
    "            #print text\n",
    "            \n",
    "        # Figure out how many pages of followers there are\n",
    "        total_pages = self.page.find_element_by_xpath(\"//body/div[1]//a[@class='page S_txt1'][last()]\")\n",
    "        totPage = int(total_pages.get_attribute('text'));\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Keep clicking on next button in order to get all the followers\n",
    "        for x in range(1, totPage):\n",
    "            # wait for the page to completely load by looking for presence of HTML element of class 'page next S_txt1 S_line1'\n",
    "            #try:\n",
    "            ui.WebDriverWait(self.page,10).until(lambda page: page.find_element_by_xpath(\"//body/div[1]//a[@class='page next S_txt1 S_line1']\"))\n",
    "            self.page.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            self.page.find_element_by_xpath(\"//body/div[1]//a[@class='page next S_txt1 S_line1']\").click() # next button\n",
    "            time.sleep(2)\n",
    "            html_list = self.page.find_element_by_css_selector(\"ul[class='follow_list']\")\n",
    "            items = html_list.find_elements_by_tag_name(\"li\")\n",
    "            for item in items:\n",
    "                text = item.text\n",
    "                followers.append(text)\n",
    "        return followers\n",
    "                #print text\n",
    "    '''        \n",
    "            except NoSuchElementException:\n",
    "                try: \n",
    "                    self.page.navigate().refresh();\n",
    "                    ui.WebDriverWait(self.page,10).until(lambda page: page.find_element_by_xpath(\"//body/div[1]//a[@class='page next S_txt1 S_line1']\"))\n",
    "                    self.page.find_element_by_xpath(\"//body/div[1]//a[@class='page next S_txt1 S_line1']\").click() # click next button\n",
    "                    time.sleep(2)\n",
    "                    html_list = self.page.find_element_by_css_selector(\"ul[class='follow_list']\")\n",
    "                    items = html_list.find_elements_by_tag_name(\"li\")\n",
    "                    for item in items:\n",
    "                        text = item.text\n",
    "                        followers.append(text)\n",
    "                        print text\n",
    "                except Exception as e:\n",
    "                    print \"Failed to find followers - please check HTML or try again. \" + str(e)\n",
    "    '''\n",
    "\n",
    "                \n",
    "    # getAccount collects all the post data for a given account ID.  \n",
    "    # end_date is a datetime object cutoff date for scraping (collect all posts after this date)\n",
    "    def getAccount(self, num_pages_to_scrape = 0): #(self, base_url, end_date, num_pages_to_scrape = 0):\n",
    "        account_data = dict()\n",
    "        # base_url = \"http://weibo.com/u/\" + str(base_url)\n",
    "        base_url = \"http://weibo.com/u/2407651573?page=1&is_all=1#_0\"\n",
    "        # Go to first page of the account \n",
    "        self.page.get(base_url)\n",
    "        #self.page.find_element_by_xpath(\"//body//a[@action-type='select_year']\").click()\n",
    "        # print \"Starting Account: %s\" % str(base_url)\n",
    "        \n",
    "        try:\n",
    "            # Wait for the account self.page to load by looking for the presence of an HTML element of class 'tb_counter'\n",
    "            ui.WebDriverWait(self.page,10).until(lambda page: page.find_element_by_xpath(\"//body//a[@action-type='select_year']\"))\n",
    "            # Collect the number of statuses posted by the account. The labels for this HTML class can change - if you get an error double chekc the weibo page. \n",
    "            counts = self.page.find_element_by_xpath(\"//body/div[1]//td[@class='S_line1'][3]/a/strong\").text\n",
    "            #counts = self.page.find_element_by_class_name('tb_counter').find_elements_by_class_name(\"S_line1\")\n",
    "            account_data['status_counts'] = int(counts)\n",
    "        except NoSuchElementException:\n",
    "            try: \n",
    "                #print (\"tried\")\n",
    "                self.page.get(\"http://weibo.com/u/2407651573?page=1&is_all=1#_0\") \n",
    "                ui.WebDriverWait(self.page,20).until(lambda page: page.find_element_by_xpath(\"//body//a[@action-type='select_year']\"))\n",
    "                counts = self.page.find_element_by_xpath(\"//body/div[1]//td[@class='S_line1'][3]/a/strong\").text\n",
    "                account_data['status_counts'] = int(counts)\n",
    "            except Exception as e:\n",
    "                print \"Failed to find counts for this account - please check HTML or try again. \" + str(e)\n",
    "            return\n",
    "        print \"Number of posts: %d\" % account_data['status_counts']\n",
    "        \n",
    "    \n",
    "        # weibo splits a user's timeline into pages, with each self.page containing 45 posts. \n",
    "        numpages = int(math.ceil(account_data['status_counts']/45.0)) \n",
    "        print numpages\n",
    "        if (num_pages_to_scrape == 0):\n",
    "            num_pages_to_scrape = numpages\n",
    "        \n",
    "        account_data['posts'] = list() # the list object in account_data (where each element is a post)\n",
    "        # Cycle through each self.page in the account and collect the posts from that self.page. \n",
    "        for p in range(1,numpages+1):\n",
    "            # If we can't or don't need to collect any more posts from this account, getPosts() will return False\n",
    "            if (p > num_pages_to_scrape):\n",
    "                break\n",
    "            print \"\\t Account %s, Page (%d/%d)\" % (base_url, p,numpages)\n",
    "            if (self.getPosts(base_url,p,account_data) == False):  #,end_date) == False):\n",
    "                break\n",
    "        return account_data\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Gets the posts from a self.page of an account. Adds these posts to account_data\n",
    "    def getPosts(self,base_url, pageNum, account_data): #, account_data): #,end_date):\n",
    "        print \"fetching: \" + base_url+ str(pageNum) #\"?is_all=1&page=\" + str(pageNum),\n",
    "        self.page.get(base_url+ \"?is_all=1&page=\" + str(pageNum)) # Navigate to the self.page of the account \n",
    "        \n",
    "        # Wait for the self.page to successfully load by checking for the presence of the \"WB_detail\" HTML element. If 10 seconds passes \n",
    "        # we reload the self.page and try again. If we try 4 or more times we abort this account. \n",
    "        timesTried = 0 \n",
    "        while True:\n",
    "            try:\n",
    "                timesTried = timesTried + 1\n",
    "                ui.WebDriverWait(self.page,10).until(lambda page: page.find_elements_by_class_name(\"WB_detail\"))\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                if (timesTried < 4):\n",
    "                    self.page.get(base_url + \"?is_all=1&page=\" + str(pageNum))\n",
    "                    pass\n",
    "                else:\n",
    "                    account_data = None\n",
    "                    return False\n",
    "                \n",
    "        print (\"done loading\")\n",
    "                \n",
    "        # Though each page of a user's timeline contains 45 posts, weibo initially only displays 15. In order to get \n",
    "        # get the other posts we have to simulate scrolling down on the page. Everytime we scroll to the bottom weibo\n",
    "        # loads another 15. We thus scroll twice to get the other 30 posts. Everytime we scroll to the bottom we check \n",
    "        # to see if the number of posts on the page has changed. We stop when there are 45 or more posts on the page or \n",
    "        # if the number of posts hasn't changed (on a profile's last page there may be fewer than 45 posts).\n",
    "        num_current = 0\n",
    "        while(num_current < 44):\n",
    "            self.page.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            num_current = len(self.page.find_elements_by_xpath(\"//*[contains(concat(' ', @class, ' '), ' WB_detail ')]\"))\n",
    "            time.sleep(3)\n",
    "            print (\"num current is \" + str(num_current))\n",
    "        print (\"done\")\n",
    "                \n",
    "        # posts_element is a list of HTML elements where each element corresponds to a post.\n",
    "        posts_element = self.page.find_elements_by_xpath(\"//*[contains(concat(' ', @class, ' '), ' WB_detail ')]\")\n",
    "        num_current = len(posts_element)\n",
    "        posts = list()\n",
    "        x = 0\n",
    "\n",
    "        # Loop through each post element, collecting the relevant data from the post. The HTML elements which contain the data we \n",
    "        # need were identified by manually looking at the source HTML. \n",
    "        for element in posts_element:\n",
    "            try:\n",
    "                post = dict()\n",
    "                post['status'] = str(element.find_element_by_class_name(\"W_f14\").text).decode(\"UTF-8\")\n",
    "                post['forwarded'] = None\n",
    "                post['attached_url'] = None\n",
    "                post['date'] = element.find_elements_by_class_name(\"WB_from\")[-1].find_element_by_tag_name(\"a\").get_attribute(\"title\")\n",
    "                post['url'] =  element.find_elements_by_class_name(\"WB_from\")[-1].find_element_by_tag_name(\"a\").get_attribute(\"href\")\n",
    "                # Get the date for a post. If it is before end_date, then return False (we don't need to collect any more posts)\n",
    "                d = datetime.strptime(post['date'].split(\" \")[0],\"%Y-%m-%d\")\n",
    "                #if (d < end_date):\n",
    "                account_data['posts'] = account_data['posts'] + posts\n",
    "                #return False\n",
    "                \n",
    "                # Get post likes, comments, and forwards counts\n",
    "                try:\n",
    "                    post_stats = element.find_element_by_xpath('../../div[2]').find_elements_by_tag_name(\"li\")\n",
    "                    for p in range(0, len(post_stats)):\n",
    "                        if ('转发' in post_stats[p].get_attribute(\"textContent\")):\n",
    "                            post['numForwards'] = re.sub(\"[^0-9]\", \"\", post_stats[p].get_attribute(\"textContent\"))\n",
    "                        if ('评论' in post_stats[p].get_attribute(\"textContent\")):\n",
    "                            post['numComments'] = re.sub(\"[^0-9]\", \"\", post_stats[p].get_attribute(\"textContent\"))\n",
    "                            post['numLikes'] = re.sub(\"[^0-9]\", \"\", post_stats[p+1].get_attribute(\"textContent\"))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                \n",
    "                # If the post contains forwarded content then it will contain and HTML element called \"WB_feed_expand\". We search for this \n",
    "                # element and collect the data about the forwarded content. \n",
    "                try: \n",
    "                    expanded = element.find_element_by_class_name(\"WB_feed_expand\")\n",
    "                    post['forwarded'] = dict()\n",
    "                    post['forwarded']['account_id'] = expanded.find_element_by_class_name(\"W_fb\").get_attribute(\"usercard\").replace(\"id=\",\"\")\n",
    "                    post['forwarded']['text'] = expanded.find_element_by_class_name(\"WB_text\").text\n",
    "                    post['forwarded']['date']=expanded.find_element_by_class_name(\"WB_from\").find_element_by_class_name(\"S_txt2\").text\n",
    "                    post['forwarded']['url'] = expanded.find_element_by_class_name(\"WB_from\").find_element_by_class_name(\"S_txt2\").get_attribute(\"href\")\n",
    "                    WB_handle = expanded.find_element_by_class_name(\"WB_handle\")\n",
    "                    post['forwarded']['post_mid'] = WB_handle.get_attribute(\"mid\")\n",
    "                    counts = WB_handle.find_elements_by_tag_name(\"li\")\n",
    "                    post['forwarded']['num_forward']= re.sub(\"[^0-9]\", \"\", counts[0].text)\n",
    "                    post['forwarded']['num_comments']= re.sub(\"[^0-9]\", \"\", counts[1].text)\n",
    "                    post['forwarded']['num_likes'] = counts[2].text\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # collect any URLs the user may have posted in the status. \n",
    "                url = element.find_elements_by_tag_name(\"a\")\n",
    "                for e in url:\n",
    "                    if (\"W_btn_b\" in e.get_attribute(\"class\")):\n",
    "                        post['attached_url'] = e.get_attribute(\"href\")\n",
    "                        \n",
    "            except Exception,e:\n",
    "                print e\n",
    "            num_current = num_current - 1\n",
    "            posts.append(post)\n",
    "        print \" collected: %d posts\" % len(posts)\n",
    "        account_data['posts'] = account_data['posts'] + posts\n",
    "        #return True\n",
    "        \n",
    "        \n",
    "    def get_forwards_comments(self, url):\n",
    "        post_data = dict()\n",
    "        post_data['url'] = url\n",
    "        self.page.get(url)\n",
    "        ids = []\n",
    "        while(True):\n",
    "            try:\n",
    "                ui.WebDriverWait(self.page,10).until(lambda page: page.find_elements_by_class_name(\"list_ul\").find_elements_by_class_name(\"WB_text\") or page.find_elements_by_class_name(\"icon_bed\"))\n",
    "            except NoSuchElementException:\n",
    "                self.page.get(post_data['url'])\n",
    "                try:\n",
    "                    ui.WebDriverWait(self.page,10).until(lambda page: page.find_elements_by_class_name(\"list_ul\").find_elements_by_class_name(\"WB_text\") or page.find_elements_by_class_name(\"icon_bed\"))\n",
    "                except:\n",
    "                    print \"No commenters/forwarders.\"\n",
    "                    return post_data\n",
    "                \n",
    "            if (len(self.page.find_elements_by_class_name(\"icon_bed\")) == 1):\n",
    "                print \"No IDs gathered.\"\n",
    "                return post_data\n",
    "            \n",
    "            accounts = self.page.find_elements_by_class_name(\"list_ul\").find_elements_by_class_name(\"WB_text\")\n",
    "            \n",
    "            for account in accounts:\n",
    "                account_id = account.find_element_by_xpath(\"./a\").get_attribute(\"usercard\").replace(\"id=\",\"\")\n",
    "                ids.append(account_id)\n",
    "                next_button = self.page.find_elements_by_class_name(\"next\")\n",
    "            if (len(next_button) == 0):\n",
    "                post_data['ids'] = ids\n",
    "                print str(len(post_data['ids'])) + \" ids collected.\"\n",
    "                return post_data\n",
    "            else:\n",
    "                next_button[0].find_element_by_xpath(\"./span\").click()\n",
    "                time.sleep(5)\n",
    "                #print \"Next Page\"\n",
    "        print (\"done\")\n",
    "        return post_data\n",
    "              \n",
    "credFile = open('credentialFile', 'r')\n",
    "w1 = w_scraper()\n",
    "w1.login(credFile)\n",
    "account_followers = list()\n",
    "account_followers = w1.getFollowers()\n",
    "print(len(account_followers))\n",
    "[x.encode('utf-8') for x in account_followers]\n",
    "with open('WeiboFollowers.txt', 'w') as f:\n",
    "    f.write(account_data)\n",
    "\n",
    "\n",
    "#account_data = list()\n",
    "#account_data = w1.getAccount()\n",
    "#post_data = w1.get_forwards_comments('http://weibo.com/u/2407651573')\n",
    "#post = get_hot_post(240765157)\n",
    "#with codecs.open(\"AccountData\", \"wb\", \"utf-8\") as temp:\n",
    "#    temp.write(account_data)\n",
    "\n",
    "#with open(\"AccountData\",'wb') as f:\n",
    "    \n",
    "    #pickle.dump(account_data,f)\n",
    "#w1.getPosts(\"http://weibo.com/u/2407651573?page=1&is_all=1#_0\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
